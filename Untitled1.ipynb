{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a7b592-606e-47db-b9d5-da9292772044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sindhujaghosh/Library/Caches/pypoetry/virtualenvs/katabatic-YBZlQpHN-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sindhujaghosh/Downloads/Data_bytes_ketabatics/Katabatic_copy\n",
      "CWD: /Users/sindhujaghosh/Downloads/Data_bytes_ketabatics/Katabatic_copy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import inspect\n",
    "import pandas as pd\n",
    "\n",
    "from utils import encode_preprocess\n",
    "from katabatic.utils.split_dataset import split_dataset\n",
    "\n",
    "from katabatic.models.medgan.models import MEDGAN\n",
    "from katabatic.models.tabsyn.models import TabSyn\n",
    "from katabatic.models.ganblr.models import GANBLR\n",
    "from katabatic.models.pategan.models import PATEGAN\n",
    "from katabatic.models.codi.models import CODI\n",
    "\n",
    "from katabatic.evaluate.tstr.evaluation import TSTREvaluation\n",
    "\n",
    "# Make sure we're in the repo root\n",
    "print(os.getcwd())\n",
    "os.chdir(\"/Users/sindhujaghosh/Downloads/Data_bytes_ketabatics/Katabatic_copy\")\n",
    "print(\"CWD:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88978c65-c1b3-4dc2-949e-7c776943d2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level:\n",
      "['train_test_data', 'trainer_great', 'Untitled1.ipynb', '.DS_Store', 'LICENSE', 'synthetic_data', 'dev_deps.py', 'Untitled.ipynb', 'Makefile', 'pyproject.toml', 'raw_data', '__pycache__', 'MODEL_CONTRIBUTIONS.md', 'README.md', 'example.ipynb', 'Results', 'sample_data', '.gitignore', 'utils.py', 'CONTRIBUTING.md', 'examples', 'scripts', 'synthetic', '.python-version', '.ipynb_checkpoints', 'poetry.lock', '.git', 'main.py', 'encoded_data', 'discretized_data', 'katabatic']\n",
      "\n",
      "raw_data contents:\n",
      "['adult.csv', 'magic.csv', 'Untitled.ipynb', 'car.csv', 'shuttle.csv', '.ipynb_checkpoints', 'car1.csv', 'nursery.csv']\n"
     ]
    }
   ],
   "source": [
    "print(\"Top-level:\")\n",
    "print(os.listdir(\".\"))\n",
    "\n",
    "print(\"\\nraw_data contents:\")\n",
    "print(os.listdir(\"raw_data\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d951f59f-6e18-495f-9f58-80e80a194118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing: raw_data/adult.csv\n",
      "Saved preprocessed discrete dataset to: encoded_data/adult.csv\n",
      "Encoded dataset saved to: encoded_data/adult.csv\n",
      "Loaded data with shape: (32561, 15)\n",
      "Saved train/test full data\n",
      "Train size: (26048, 15), Test size: (6513, 15)\n",
      "Train label distribution:\n",
      " 14\n",
      "0    0.759175\n",
      "1    0.240825\n",
      "Name: proportion, dtype: float64\n",
      "Test label distribution:\n",
      " 14\n",
      "0    0.759251\n",
      "1    0.240749\n",
      "Name: proportion, dtype: float64\n",
      "Saved X/y split\n",
      "Training shape: (26048, 14) (26048,)\n",
      "Test shape: (6513, 14) (6513,)\n",
      "\n",
      "train_test_data contents: ['X_num_train.npy', 'X_num_test.npy', 'y_train.npy', 'train_full.csv', 'x_train.csv', 'test_full.csv', 'y_test.npy', 'y_train.csv', 'y_test.csv', 'x_test.csv']\n"
     ]
    }
   ],
   "source": [
    "# 1. Encode / preprocess adult.csv\n",
    "raw_path = \"raw_data/adult.csv\"\n",
    "encoded_path = \"encoded_data/adult.csv\"\n",
    "\n",
    "encode_preprocess(raw_path, encoded_path)\n",
    "print(\"Encoded dataset saved to:\", encoded_path)\n",
    "\n",
    "# 2. Train/test split into X/y + full CSVs\n",
    "output_dir = \"train_test_data\"\n",
    "\n",
    "split_dataset(\n",
    "    input_csv=encoded_path,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "\n",
    "print(\"\\ntrain_test_data contents:\", os.listdir(output_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967effb9-cc3c-429a-a044-918aff35cc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26048, 14), (6513, 14), (26048,), (6513,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(os.path.join(output_dir, \"x_train.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(output_dir, \"y_train.csv\")).values.ravel()\n",
    "X_test  = pd.read_csv(os.path.join(output_dir, \"x_test.csv\"))\n",
    "y_test  = pd.read_csv(os.path.join(output_dir, \"y_test.csv\")).values.ravel()\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1804345b-de37-44b5-adae-4293cce5c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect\n",
    "\n",
    "def run_generator_pipeline(model_cls, model_name, dataset_dir, synthetic_root, model_kwargs=None):\n",
    "    \"\"\"\n",
    "    Train a generator model on dataset_dir and write synthetic data to \n",
    "    synthetic_root/model_name.\n",
    "\n",
    "    It auto-detects whether the model.train(...) expects:\n",
    "        - dataset_dir=...\n",
    "        - or data_dir=...\n",
    "    and always passes synthetic_dir if supported.\n",
    "\n",
    "    Returns:\n",
    "        model, synthetic_dir\n",
    "    \"\"\"\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    # e.g. synthetic_data/adult/medgan\n",
    "    synthetic_dir = os.path.join(synthetic_root, model_name)\n",
    "    os.makedirs(synthetic_dir, exist_ok=True)\n",
    "\n",
    "    # Instantiate model\n",
    "    model = model_cls(**model_kwargs)\n",
    "\n",
    "    print(f\"\\n=== Training {model_name} ===\")\n",
    "    print(\"dataset_dir :\", dataset_dir)\n",
    "    print(\"synthetic_dir:\", synthetic_dir)\n",
    "\n",
    "    # Inspect train signature\n",
    "    train_sig = inspect.signature(model.train)\n",
    "    params = train_sig.parameters\n",
    "\n",
    "    call_kwargs = {}\n",
    "\n",
    "    # Map our dataset_dir -> whatever the model expects\n",
    "    if \"dataset_dir\" in params:\n",
    "        call_kwargs[\"dataset_dir\"] = dataset_dir\n",
    "    elif \"data_dir\" in params:\n",
    "        call_kwargs[\"data_dir\"] = dataset_dir\n",
    "    else:\n",
    "        # fallback: first non-self positional parameter\n",
    "        first_param = [p for p in params if p != \"self\"][0]\n",
    "        call_kwargs[first_param] = dataset_dir\n",
    "\n",
    "    # Add synthetic_dir if supported\n",
    "    if \"synthetic_dir\" in params:\n",
    "        call_kwargs[\"synthetic_dir\"] = synthetic_dir\n",
    "\n",
    "    # Call train with the detected kwargs\n",
    "    print(\"Calling train with:\", call_kwargs)\n",
    "    model.train(**call_kwargs)\n",
    "\n",
    "    print(f\"{model_name} training completed. Synthetic data saved to: {synthetic_dir}\")\n",
    "    return model, synthetic_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c9dec6-9b39-4d97-ae46-883beab67942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:katabatic.models.medgan.models:================================================================================\n",
      "INFO:katabatic.models.medgan.models:Training MedGAN Model\n",
      "INFO:katabatic.models.medgan.models:================================================================================\n",
      "INFO:katabatic.models.medgan.models:Loaded training data: (26048, 14)\n",
      "INFO:katabatic.models.medgan.models:Data normalized to [0, 1] range\n",
      "INFO:katabatic.models.medgan.models:Original range: [0.00, 1484705.00]\n",
      "INFO:katabatic.models.medgan.models:Normalized range: [0.00, 1.00]\n",
      "INFO:katabatic.models.medgan.models:\n",
      "Phase 1: Pretraining Autoencoder for 150 epochs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training medgan ===\n",
      "dataset_dir : train_test_data\n",
      "synthetic_dir: synthetic_data/adult/medgan\n",
      "Calling train with: {'dataset_dir': 'train_test_data', 'synthetic_dir': 'synthetic_data/adult/medgan'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:katabatic.models.medgan.models:Epoch 1/150: AE Loss = 0.459054\n",
      "INFO:katabatic.models.medgan.models:Epoch 10/150: AE Loss = 0.325585\n",
      "INFO:katabatic.models.medgan.models:Epoch 20/150: AE Loss = 0.323615\n",
      "INFO:katabatic.models.medgan.models:Epoch 30/150: AE Loss = 0.322873\n",
      "INFO:katabatic.models.medgan.models:Epoch 40/150: AE Loss = 0.322578\n",
      "INFO:katabatic.models.medgan.models:Epoch 50/150: AE Loss = 0.322313\n",
      "INFO:katabatic.models.medgan.models:Epoch 60/150: AE Loss = 0.322141\n",
      "INFO:katabatic.models.medgan.models:Epoch 70/150: AE Loss = 0.322078\n",
      "INFO:katabatic.models.medgan.models:Epoch 80/150: AE Loss = 0.321955\n",
      "INFO:katabatic.models.medgan.models:Epoch 90/150: AE Loss = 0.321866\n",
      "INFO:katabatic.models.medgan.models:Epoch 100/150: AE Loss = 0.321785\n",
      "INFO:katabatic.models.medgan.models:Epoch 110/150: AE Loss = 0.321715\n",
      "INFO:katabatic.models.medgan.models:Epoch 120/150: AE Loss = 0.321679\n",
      "INFO:katabatic.models.medgan.models:Epoch 130/150: AE Loss = 0.321626\n",
      "INFO:katabatic.models.medgan.models:Epoch 140/150: AE Loss = 0.321579\n",
      "INFO:katabatic.models.medgan.models:Epoch 150/150: AE Loss = 0.321558\n",
      "INFO:katabatic.models.medgan.models:\n",
      "Phase 2: Training GAN for 1500 epochs...\n",
      "INFO:katabatic.models.medgan.models:Epoch 1/1500: D Loss = 0.565430, G Loss = 4.146994\n",
      "INFO:katabatic.models.medgan.models:Epoch 100/1500: D Loss = 0.154494, G Loss = 4.819604\n",
      "INFO:katabatic.models.medgan.models:Epoch 200/1500: D Loss = 0.201136, G Loss = 3.902199\n",
      "INFO:katabatic.models.medgan.models:Epoch 300/1500: D Loss = 0.182037, G Loss = 4.008646\n",
      "INFO:katabatic.models.medgan.models:Epoch 400/1500: D Loss = 0.172816, G Loss = 3.937766\n",
      "INFO:katabatic.models.medgan.models:Epoch 500/1500: D Loss = 0.167949, G Loss = 4.118723\n",
      "INFO:katabatic.models.medgan.models:Epoch 600/1500: D Loss = 0.155965, G Loss = 4.148010\n",
      "INFO:katabatic.models.medgan.models:Epoch 700/1500: D Loss = 0.135855, G Loss = 4.337358\n",
      "INFO:katabatic.models.medgan.models:Epoch 800/1500: D Loss = 0.145800, G Loss = 4.297365\n",
      "INFO:katabatic.models.medgan.models:Epoch 900/1500: D Loss = 0.152059, G Loss = 4.118275\n",
      "INFO:katabatic.models.medgan.models:Epoch 1000/1500: D Loss = 0.137718, G Loss = 4.285996\n",
      "INFO:katabatic.models.medgan.models:Epoch 1100/1500: D Loss = 0.129017, G Loss = 4.527506\n",
      "INFO:katabatic.models.medgan.models:Epoch 1200/1500: D Loss = 0.134234, G Loss = 4.452874\n",
      "INFO:katabatic.models.medgan.models:Epoch 1300/1500: D Loss = 0.129833, G Loss = 4.524048\n",
      "INFO:katabatic.models.medgan.models:Epoch 1400/1500: D Loss = 0.131742, G Loss = 4.303398\n",
      "INFO:katabatic.models.medgan.models:Epoch 1500/1500: D Loss = 0.128558, G Loss = 4.640714\n",
      "INFO:katabatic.models.medgan.models:\n",
      "Generating 26048 synthetic samples...\n",
      "WARNING:katabatic.models.medgan.models:Missing classes in synthetic data: {1}\n",
      "INFO:katabatic.models.medgan.models:Adding dummy samples to ensure all classes are present...\n",
      "INFO:katabatic.models.medgan.models:Added 1 dummy samples\n",
      "INFO:katabatic.models.medgan.models:\n",
      "Synthetic data saved to: synthetic_data/adult/medgan\n",
      "INFO:katabatic.models.medgan.models:Training complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medgan training completed. Synthetic data saved to: synthetic_data/adult/medgan\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"train_test_data\"\n",
    "synthetic_root = \"synthetic_data/adult\"\n",
    "\n",
    "medgan_kwargs = dict(\n",
    "    encoder_dim=128,\n",
    "    latent_dim=128,\n",
    "    generator_hidden_dim=256,\n",
    "    discriminator_hidden_dim=256,\n",
    "    generator_num_layers=3,\n",
    "    discriminator_num_layers=3,\n",
    "    ae_pretrain_epochs=150,\n",
    "    gan_epochs=1500,\n",
    "    batch_size=256,\n",
    "    ae_lr=1e-3,\n",
    "    generator_lr=5e-4,\n",
    "    discriminator_lr=5e-4,\n",
    "    dropout=0.1,\n",
    "    bn_decay=0.99,\n",
    "    random_state=42,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "medgan, medgan_synth_dir = run_generator_pipeline(\n",
    "    model_cls=MEDGAN,\n",
    "    model_name=\"medgan\",\n",
    "    dataset_dir=dataset_dir,\n",
    "    synthetic_root=synthetic_root,\n",
    "    model_kwargs=medgan_kwargs,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ba91a9-191f-4280-8e39-8200deec1099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train_test_data before creating .npy:\n",
      "['X_num_train.npy', 'X_num_test.npy', 'y_train.npy', 'train_full.csv', 'x_train.csv', 'test_full.csv', 'y_test.npy', 'y_train.csv', 'y_test.csv', 'x_test.csv']\n",
      "\n",
      "Created .npy files for TabSyn.\n",
      "Files in train_test_data now:\n",
      "['X_num_train.npy', 'X_num_test.npy', 'y_train.npy', 'train_full.csv', 'x_train.csv', 'test_full.csv', 'y_test.npy', 'y_train.csv', 'y_test.csv', 'x_test.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = \"train_test_data\"\n",
    "\n",
    "print(\"Files in train_test_data before creating .npy:\")\n",
    "print(os.listdir(output_dir))\n",
    "\n",
    "# Load the CSV splits we already created\n",
    "X_train_df = pd.read_csv(os.path.join(output_dir, \"x_train.csv\"))\n",
    "X_test_df  = pd.read_csv(os.path.join(output_dir, \"x_test.csv\"))\n",
    "y_train_df = pd.read_csv(os.path.join(output_dir, \"y_train.csv\"))\n",
    "y_test_df  = pd.read_csv(os.path.join(output_dir, \"y_test.csv\"))\n",
    "\n",
    "# Convert to numpy\n",
    "X_train = X_train_df.values.astype(\"float32\")\n",
    "X_test  = X_test_df.values.astype(\"float32\")\n",
    "y_train = y_train_df.values.ravel()\n",
    "y_test  = y_test_df.values.ravel()\n",
    "\n",
    "# Save in the format TabSyn expects\n",
    "np.save(os.path.join(output_dir, \"X_num_train.npy\"), X_train)\n",
    "np.save(os.path.join(output_dir, \"X_num_test.npy\"), X_test)\n",
    "np.save(os.path.join(output_dir, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(output_dir, \"y_test.npy\"), y_test)\n",
    "\n",
    "print(\"\\nCreated .npy files for TabSyn.\")\n",
    "print(\"Files in train_test_data now:\")\n",
    "print(os.listdir(output_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a9a2889-2b32-4ecf-aede-5be6629eacef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training tabsyn ===\n",
      "dataset_dir : train_test_data\n",
      "synthetic_dir: synthetic_data/adult/tabsyn\n",
      "Calling train with: {'data_dir': 'train_test_data'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TabSyn] Synthetic data saved:\n",
      "  X -> synthetic/train_test_data/tabsyn/x_synth.csv\n",
      "  y -> synthetic/train_test_data/tabsyn/y_synth.csv\n",
      "tabsyn training completed. Synthetic data saved to: synthetic_data/adult/tabsyn\n"
     ]
    }
   ],
   "source": [
    "tabsyn, tabsyn_synth = run_generator_pipeline(\n",
    "    model_cls=TabSyn,\n",
    "    model_name=\"tabsyn\",\n",
    "    dataset_dir=dataset_dir,\n",
    "    synthetic_root=synthetic_root\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d647df55-4b84-4e0f-840d-e505108c72f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training ganblr ===\n",
      "dataset_dir : train_test_data\n",
      "synthetic_dir: synthetic_data/adult/ganblr\n",
      "Calling train with: {'dataset': 'train_test_data'}\n",
      "Loaded X shape: (26048, 14), y shape: (26048,)\n",
      "warmup run:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sindhujaghosh/Library/Caches/pypoetry/virtualenvs/katabatic-YBZlQpHN-py3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ganblr, ganblr_synth = run_generator_pipeline(\n",
    "    model_cls=GANBLR,\n",
    "    model_name=\"ganblr\",\n",
    "    dataset_dir=dataset_dir,\n",
    "    synthetic_root=synthetic_root\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607add0-658a-46c0-960c-0c6b40bf5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "ganblr, ganblr_synth = run_generator_pipeline(\n",
    "    model_cls=GANBLR,\n",
    "    model_name=\"ganblr\",\n",
    "    dataset_dir=dataset_dir,\n",
    "    synthetic_root=synthetic_root\n",
    ")\n",
    "\n",
    "pategan, pategan_synth = run_generator_pipeline(\n",
    "    model_cls=PATEGAN,\n",
    "    model_name=\"pategan\",\n",
    "    dataset_dir=dataset_dir,\n",
    "    synthetic_root=synthetic_root\n",
    ")\n",
    "\n",
    "codi, codi_synth = run_generator_pipeline(\n",
    "    model_cls=CODI,\n",
    "    model_name=\"codi\",\n",
    "    dataset_dir=dataset_dir,\n",
    "    synthetic_root=synthetic_root\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d902bd1-b70e-4fd8-9084-80f0fbef0ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
