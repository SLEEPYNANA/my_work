{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Reduce parallelism for stability in notebooks\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
        "try:\n",
        "    import torch\n",
        "    torch.set_num_threads(1)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Resolve project root and ensure it's on sys.path\n",
        "ROOT = Path.cwd().resolve()\n",
        "for _ in range(5):\n",
        "    if (ROOT / \"pyproject.toml\").exists() or (ROOT / \"raw_data\").exists():\n",
        "        break\n",
        "    ROOT = ROOT.parent\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "\n",
        "from utils import discretize_preprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing: /Users/vikumdabare/Documents/Work/Katabatic/katabatic/raw_data/car.csv\n",
            "Saved preprocessed discrete dataset to: /Users/vikumdabare/Documents/Work/Katabatic/katabatic/discretized_data/car.csv\n"
          ]
        }
      ],
      "source": [
        "# Preprocess data\n",
        "from pathlib import Path\n",
        "\n",
        "dataset_path = ROOT / \"raw_data\" / \"car.csv\"\n",
        "output_path = ROOT / \"discretized_data\" / \"car.csv\"\n",
        "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "discretize_preprocess(str(dataset_path), str(output_path))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vikumdabare/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded data with shape: (1728, 7)\n",
            "Saved train/test full data\n",
            "Train size: (1382, 7), Test size: (346, 7)\n",
            "Train label distribution:\n",
            " 6\n",
            "2    0.700434\n",
            "0    0.222142\n",
            "1    0.039797\n",
            "3    0.037627\n",
            "Name: proportion, dtype: float64\n",
            "Test label distribution:\n",
            " 6\n",
            "2    0.699422\n",
            "0    0.222543\n",
            "1    0.040462\n",
            "3    0.037572\n",
            "Name: proportion, dtype: float64\n",
            "Saved X/y split\n",
            "Training shape: (1382, 6) (1382,)\n",
            "Test shape: (346, 6) (346,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vikumdabare/Documents/Work/Katabatic/katabatic/katabatic/models/great/models.py:264: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `GReaTTrainer.__init__`. Use `processing_class` instead.\n",
            "  great_trainer = GReaTTrainer(\n",
            "/Users/vikumdabare/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='1382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 501/1382 04:12 < 07:25, 1.98 it/s, Epoch 0.72/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "[enforce fail at inline_container.cc:664] . unexpected pos 895508224 vs 895508116",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/torch/serialization.py:967\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    966\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/torch/serialization.py:1268\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[39m\n\u001b[32m   1267\u001b[39m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1268\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: [enforce fail at inline_container.cc:863] . PytorchStreamWriter failed writing file data/130: file write failed",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# GReaT requires an llm argument; wrap with a lambda for the pipeline\u001b[39;00m\n\u001b[32m     12\u001b[39m pipeline = TrainTestSplitPipeline(model=\u001b[38;5;28;01mlambda\u001b[39;00m: GReaT(llm=\u001b[33m'\u001b[39m\u001b[33mgpt2\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m result = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_csv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43msynthetic_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynthetic_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreal_test_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreal_test_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/katabatic/pipeline/train_test_split/pipeline.py:38\u001b[39m, in \u001b[36mTrainTestSplitPipeline.run\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m split_dataset(input_csv, output_dir, *args, **kwargs)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Train the model (may consume extra kwargs like 'config')\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mcurrent_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Filter kwargs for evaluations to avoid unexpected params (e.g., 'config')\u001b[39;00m\n\u001b[32m     41\u001b[39m eval_kwargs = \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/katabatic/models/great/models.py:183\u001b[39m, in \u001b[36mGReaT.train\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28mself\u001b[39m.batch_size = \u001b[32m2\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;66;03m# Generate synthetic data of equal size on CPU to avoid GPU issues\u001b[39;00m\n\u001b[32m    186\u001b[39m n_rows = \u001b[38;5;28mlen\u001b[39m(df_train)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/katabatic/models/great/models.py:274\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(self, data, column_names, conditional_col, resume_from_checkpoint)\u001b[39m\n\u001b[32m    261\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mCreate GReaT Trainer...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    262\u001b[39m training_args = TrainingArguments(\n\u001b[32m    263\u001b[39m     \u001b[38;5;28mself\u001b[39m.experiment_dir,\n\u001b[32m    264\u001b[39m     num_train_epochs=\u001b[38;5;28mself\u001b[39m.epochs,\n\u001b[32m    265\u001b[39m     per_device_train_batch_size=\u001b[38;5;28mself\u001b[39m.batch_size,\n\u001b[32m    266\u001b[39m     **\u001b[38;5;28mself\u001b[39m.train_hyperparameters,\n\u001b[32m    267\u001b[39m )\n\u001b[32m    268\u001b[39m great_trainer = GReaTTrainer(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    270\u001b[39m     training_args,\n\u001b[32m    271\u001b[39m     train_dataset=great_ds,\n\u001b[32m    272\u001b[39m     tokenizer=\u001b[38;5;28mself\u001b[39m.tokenizer,\n\u001b[32m    273\u001b[39m     data_collator=GReaTDataCollator(\u001b[38;5;28mself\u001b[39m.tokenizer),\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m )\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[32m    277\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mStart training...\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/transformers/trainer.py:2206\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2204\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2207\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/transformers/trainer.py:2623\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2621\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m + steps_skipped) / steps_in_epoch\n\u001b[32m   2622\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2623\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2632\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2634\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/transformers/trainer.py:3103\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3100\u001b[39m         \u001b[38;5;28mself\u001b[39m.control.should_save = is_new_best_metric\n\u001b[32m   3102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_save:\n\u001b[32m-> \u001b[39m\u001b[32m3103\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3104\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_save(\u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/transformers/trainer.py:3211\u001b[39m, in \u001b[36mTrainer._save_checkpoint\u001b[39m\u001b[34m(self, model, trial)\u001b[39m\n\u001b[32m   3207\u001b[39m         \u001b[38;5;28mself\u001b[39m.state.best_model_checkpoint = best_checkpoint_dir\n\u001b[32m   3209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_only_model:\n\u001b[32m   3210\u001b[39m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3211\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3212\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_scaler(output_dir)\n\u001b[32m   3213\u001b[39m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/transformers/trainer.py:3338\u001b[39m, in \u001b[36mTrainer._save_optimizer_and_scheduler\u001b[39m\u001b[34m(self, output_dir)\u001b[39m\n\u001b[32m   3333\u001b[39m     save_fsdp_optimizer(\n\u001b[32m   3334\u001b[39m         \u001b[38;5;28mself\u001b[39m.accelerator.state.fsdp_plugin, \u001b[38;5;28mself\u001b[39m.accelerator, \u001b[38;5;28mself\u001b[39m.optimizer, \u001b[38;5;28mself\u001b[39m.model, output_dir\n\u001b[32m   3335\u001b[39m     )\n\u001b[32m   3336\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.should_save:\n\u001b[32m   3337\u001b[39m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3338\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3340\u001b[39m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[32m   3341\u001b[39m is_deepspeed_custom_scheduler = \u001b[38;5;28mself\u001b[39m.is_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   3342\u001b[39m     \u001b[38;5;28mself\u001b[39m.lr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[32m   3343\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/torch/serialization.py:966\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    963\u001b[39m     f = os.fspath(f)\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m    972\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Katabatic/katabatic/.venv/lib/python3.11/site-packages/torch/serialization.py:798\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__exit__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m798\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.file_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    800\u001b[39m         \u001b[38;5;28mself\u001b[39m.file_stream.close()\n",
            "\u001b[31mRuntimeError\u001b[39m: [enforce fail at inline_container.cc:664] . unexpected pos 895508224 vs 895508116"
          ]
        }
      ],
      "source": [
        "from katabatic.pipeline.train_test_split.pipeline import TrainTestSplitPipeline\n",
        "from katabatic.models.great.models import GReaT\n",
        "\n",
        "# Run pipeline\n",
        "input_csv = str(output_path)\n",
        "output_dir = str(ROOT / \"sample_data\" / \"car\")\n",
        "real_test_dir = output_dir\n",
        "\n",
        "synthetic_dir = str(ROOT / \"synthetic\" / \"car\" / \"great\")\n",
        "\n",
        "# Use a tiny model and minimal training for stability\n",
        "pipeline = TrainTestSplitPipeline(\n",
        "    model=lambda: GReaT(\n",
        "        llm='sshleifer/tiny-gpt2',\n",
        "        epochs=1,\n",
        "        batch_size=1,\n",
        "        report_to=[],\n",
        "    )\n",
        ")\n",
        "result = pipeline.run(\n",
        "    input_csv=input_csv,\n",
        "    output_dir=output_dir,\n",
        "    synthetic_dir=synthetic_dir,\n",
        "    real_test_dir=real_test_dir,\n",
        ")\n",
        "print(result)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
